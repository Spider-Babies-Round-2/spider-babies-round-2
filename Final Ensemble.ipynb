{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Ensemble Learner\n",
    "\n",
    "## What's happening here?\n",
    "\n",
    "You'll see that the first three sections creates learners.   \n",
    "This does not mean that the learners created here are the ones that go in the ensemble. I believe our Random Forest is the only one which is created in advance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest made up of DTrees (learner #1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltools as ml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=',')\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=',')\n",
    "\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X,Y,0.7)\n",
    "\n",
    "X_numeric = Xtr[:,:41]\n",
    "X_discrete = Xtr[:,41:69]\n",
    "X_binary = Xtr[:,69:-1]\n",
    "\n",
    "Xtr_kaggle = np.genfromtxt('data/X_train.txt', delimiter=',')\n",
    "Ytr_kaggle = np.genfromtxt('data/Y_train.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaggedTree(ml.base.classifier):\n",
    "    def __init__(self, learners):\n",
    "        \"\"\"Constructs a BaggedTree class with a set of learners. \"\"\"\n",
    "        self.learners = learners\n",
    "    \n",
    "    def predictSoft(self, X):\n",
    "        \"\"\"Predicts the probabilities with each bagged learner and average over the results. \"\"\"\n",
    "        n_bags = len(self.learners)\n",
    "        preds = [self.learners[l].predictSoft(X) for l in range(n_bags)]\n",
    "        return np.mean(preds, axis=0)\n",
    "\n",
    "bootstrap_sample_size = 50\n",
    "\n",
    "m,n = Xtr.shape\n",
    "\n",
    "bag_numbers = np.array([5,10,25,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of numeric learners = 33\n",
      "# of discrete learners = 10\n",
      "# of binary learners = 5\n",
      "---- Total number of bags for this run: 48\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Xtr_kaggle = Xtr_kaggle[:,:41]\n",
    "\n",
    "Xtr_kaggle,Ytr_kaggle = ml.shuffleData(Xtr_kaggle,Ytr_kaggle)\n",
    "\n",
    "#final_num_bags = 50\n",
    "#final_classifiers = [None]*final_num_bags\n",
    "\n",
    "num_bags = 50\n",
    "\n",
    "num_numeric_learners = int(round(num_bags / 1.5))\n",
    "num_discrete_learners = int(round(num_bags / 5))\n",
    "num_binary_learners = int(round(num_bags / 10))\n",
    "    \n",
    "# update num bags based on number of learners \n",
    "# (only slight deviation based on the algorithm and rounding)\n",
    "num_bags = num_numeric_learners + num_discrete_learners + num_binary_learners\n",
    "\n",
    "print(f\"# of numeric learners = {num_numeric_learners}\")\n",
    "print(f\"# of discrete learners = {num_discrete_learners}\")\n",
    "print(f\"# of binary learners = {num_binary_learners}\")\n",
    "print(f\"---- Total number of bags for this run: {num_bags}\")\n",
    "\n",
    "\n",
    "classifiers = [None]*num_bags\n",
    "\n",
    "# keep track of which number classifier we are on\n",
    "classifiers_index = 0\n",
    "\n",
    "for i in range(num_numeric_learners):\n",
    "    #print(\"classifier index\", classifiers_index)\n",
    "    Xi,Yi = ml.bootstrapData(Xtr, Ytr)\n",
    "\n",
    "    # insert classifier into list\n",
    "    classifiers[classifiers_index] = ml.dtree.treeClassify(Xi, Yi, minParent=400, minLeaf=100, maxDepth=50)\n",
    "    classifiers_index += 1\n",
    "\n",
    "for i in range(num_discrete_learners):\n",
    "    #print(\"classifier index\", classifiers_index)\n",
    "    Xi,Yi = ml.bootstrapData(Xtr, Ytr)\n",
    "\n",
    "    # insert classifier into list\n",
    "    classifiers[classifiers_index] = ml.dtree.treeClassify(Xi, Yi, minParent=300, minLeaf=100, maxDepth=10)\n",
    "    classifiers_index += 1\n",
    "\n",
    "for i in range(num_binary_learners):\n",
    "    #print(\"classifier index\", classifiers_index)\n",
    "    Xi,Yi = ml.bootstrapData(Xtr, Ytr)\n",
    "\n",
    "    # insert classifier into list\n",
    "    classifiers[classifiers_index] = ml.dtree.treeClassify(Xi, Yi, minParent=16, minLeaf=50, maxDepth=10)\n",
    "    classifiers_index += 1\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "kaggle_bagged_tree = BaggedTree(classifiers)\n",
    "kaggle_bagged_tree.classes = np.unique(Ytr_kaggle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Learner (Learner #2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mltools as ml\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=',')\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=',')\n",
    "\n",
    "np.random.seed(0)\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "X_numeric = X[:,:41]\n",
    "X_categorical = X[:,41:69]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X_categorical,Y,0.7)\n",
    "Xtr_scaled = scaler.fit_transform(Xtr, Ytr)\n",
    "Xva_scaled = scaler.fit_transform(Xva,Yva)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=410, weights='distance')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_knn = KNeighborsClassifier(n_neighbors=410, weights='distance')\n",
    "sklearn_knn.fit(Xtr_scaled, Ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Learner (Learner #3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier as mlpc\n",
    "from sklearn.preprocessing import StandardScaler,QuantileTransformer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "\n",
    "import mltools as ml\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=',')\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=',')\n",
    "np.random.seed(0)\n",
    "\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "X = X[:,:41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "transformer = QuantileTransformer()\n",
    "\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X,Y,0.7)\n",
    "Xtr_scaled = scaler.fit_transform(Xtr, Ytr)\n",
    "Xva_scaled = scaler.fit_transform(Xva,Yva)\n",
    "Xtr_transformed = transformer.fit_transform(Xtr)\n",
    "Xva_transformed = transformer.fit_transform(Xva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.05, hidden_layer_sizes=(5, 5, 10),\n",
       "              learning_rate='adaptive', max_iter=10000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner = mlpc(max_iter=10000, alpha=0.05, hidden_layer_sizes=(5,5,10), activation='tanh', learning_rate= 'adaptive')\n",
    "learner.fit(Xtr_transformed,Ytr) #the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte = np.genfromtxt('data/X_test.txt', delimiter=',')\n",
    "Xte_transformed = transformer.fit_transform(Xte[:,:41])\n",
    "Yte_hat = np.vstack((np.arange(Xte_transformed.shape[0]), learner.predict(Xte_transformed))).T\n",
    "\n",
    "np.savetxt('Y_submit_neural_network.txt', Yte_hat,'%d, %.2f',comments='', header='Id,Predicted', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Ensemble class\n",
    "In this case, we are using the BaggedTree class to implement a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaggedTree(ml.base.classifier):\n",
    "    def __init__(self, learners):\n",
    "        \"\"\"Constructs a BaggedTree class with a set of learners. \"\"\"\n",
    "        self.learners = learners\n",
    "    \n",
    "    def predictSoft(self, X):\n",
    "        \"\"\"Predicts the probabilities with each bagged learner and average over the results. \"\"\"\n",
    "        n_bags = len(self.learners)\n",
    "        preds = [self.learners[l].predict(X) for l in range(n_bags)]\n",
    "        return np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mltools as ml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=',')\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=',')\n",
    "\n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X,Y,0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "\n",
    "I'm giving us options to use three types of data:  \n",
    "- Raw (`Xtr`/`Xva`)  \n",
    "- Scaled (`Xtr_scaled`,`Xva_scaled`)  \n",
    "- Transformed (`Xtr_transformed`/`Xva_transformed`)\n",
    "\n",
    "**KNOW THIS:** Whatever preprocessing actions we do to the training data MUST BE DONE ON THE FINAL `Xte` ON WHICH OUR FINAL ENSEMBLE MAKES PREDICTIONS FOR KAGGLE SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "transformer = QuantileTransformer()\n",
    "\n",
    "Xtr, Xva, Ytr, Yva = ml.splitData(X,Y,0.7)\n",
    "Xtr_scaled = scaler.fit_transform(Xtr, Ytr)\n",
    "Xva_scaled = scaler.fit_transform(Xva,Yva)\n",
    "Xtr_transformed = transformer.fit_transform(Xtr)\n",
    "Xva_transformed = transformer.fit_transform(Xva)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the list of classifiers for our Final Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of numeric learners = 33\n",
      "# of discrete learners = 5\n",
      "# of binary learners = 10\n",
      "---- Total number of bags for this run: 48\n"
     ]
    }
   ],
   "source": [
    "bootstrap_sample_size = 50\n",
    "\n",
    "\n",
    "num_bags = 50\n",
    "\n",
    "num_random_forest_learners = int(round(num_bags / 1.5))\n",
    "num_knn_learners = int(round(num_bags / 10))\n",
    "num_neural_network_learners = int(round(num_bags / 5))\n",
    "    \n",
    "# update num bags based on number of learners \n",
    "# (only slight deviation based on the algorithm and rounding)\n",
    "num_bags = num_random_forest_learners + num_knn_learners + num_neural_network_learners\n",
    "\n",
    "print(f\"# of numeric learners = {num_random_forest_learners}\")\n",
    "print(f\"# of discrete learners = {num_knn_learners}\")\n",
    "print(f\"# of binary learners = {num_neural_network_learners}\")\n",
    "print(f\"---- Total number of bags for this run: {num_bags}\")\n",
    "\n",
    "\n",
    "final_classifiers = [None]*num_bags\n",
    "\n",
    "# keep track of which number classifier we are on\n",
    "classifiers_index = 0\n",
    "\n",
    "\n",
    "# Populate classifier list with our random forest learners\n",
    "for i in range(num_random_forest_learners):\n",
    "    Xi,Yi = ml.bootstrapData(Xtr, Ytr)\n",
    "\n",
    "    # insert classifier into list\n",
    "    \n",
    "    # WE CAN'T TRAIN OUR RANDOM FOREST AGAIN\n",
    "    final_classifiers[classifiers_index] = kaggle_bagged_tree\n",
    "    classifiers_index += 1\n",
    "\n",
    "for i in range(num_knn_learners):\n",
    "    Xi,Yi = ml.bootstrapData(Xtr, Ytr)\n",
    "\n",
    "    # insert classifier into list\n",
    "    knn = KNeighborsClassifier(n_neighbors=410, weights='distance')\n",
    "    knn.fit(Xi, Yi)\n",
    "    final_classifiers[classifiers_index] = knn\n",
    "    classifiers_index += 1\n",
    "\n",
    "for i in range(num_neural_network_learners):\n",
    "    Xi,Yi = ml.bootstrapData(Xtr, Ytr)\n",
    "\n",
    "    # insert classifier into list\n",
    "    neural_network_learner = mlpc(max_iter=10000, alpha=0.05, hidden_layer_sizes=(5,5,10), activation='tanh', learning_rate= 'adaptive')\n",
    "    neural_network_learner.fit(Xi,Yi) #the training\n",
    "    final_classifiers[classifiers_index] = neural_network_learner\n",
    "    classifiers_index += 1\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "final_ensemble = BaggedTree(final_classifiers)\n",
    "final_ensemble.classes = np.unique(Ytr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Projects\\spider-babies-round-2\\mltools\\base.py\u001b[0m in \u001b[0;36mauc\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m                  \u001b[1;31m# compute 'response' (soft binary classification score)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m       \u001b[0msoft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictSoft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# p(class = 2nd)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# or we can use 'hard' binary prediction if soft is unavailable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-bf979b23a96d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_ensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXva\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYva\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"auc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Projects\\spider-babies-round-2\\mltools\\base.py\u001b[0m in \u001b[0;36mauc\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    117\u001b[0m       \u001b[0msoft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictSoft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# p(class = 2nd)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# or we can use 'hard' binary prediction if soft is unavailable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m       \u001b[0msoft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m             \u001b[1;31m# ensure soft is the correct shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Projects\\spider-babies-round-2\\mltools\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mimplemented\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mby\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mit\u001b[0m \u001b[0muses\u001b[0m \u001b[0mpredictSoft\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconverts\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmost\u001b[0m \u001b[0mlikely\u001b[0m \u001b[1;32mclass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \"\"\"\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictSoft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m      \u001b[1;31m# find most likely class (index)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m                 \u001b[1;31m# convert to saved class values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nananananate\\projects\\spider-babies-round-2\\env\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m     \"\"\"\n\u001b[1;32m-> 1188\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nananananate\\projects\\spider-babies-round-2\\env\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "auc = final_ensemble.auc(Xva, Yva)\n",
    "\n",
    "print(\"auc\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
